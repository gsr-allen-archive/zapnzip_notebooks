{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "In this notebook, I apply UMAP to EEG data to see if different mouse states are captured well without any other analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, patches\n",
    "from scipy import signal\n",
    "import umap\n",
    "\n",
    "from tbd_eeg.data_analysis.eegutils import *\n",
    "from tbd_eeg.data_analysis.Utilities import utilities as utils\n",
    "import differentiation\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_cms = {\n",
    "    'pre' : cm.Reds,\n",
    "    'iso_high' : cm.PuOr,\n",
    "    'iso_low' : cm.PuOr_r,\n",
    "    'early_recovery': cm.Blues,\n",
    "    'late_recovery' : cm.Greens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/allen/programs/braintv/workgroups/nc-ophys/Leslie/eeg_pilot/mouse496220/pilot2_2020.01.16/recording1/\"\n",
    "\n",
    "# set the sample_rate for all data analysis\n",
    "sample_rate = 2500\n",
    "\n",
    "# load experiment metadata and eeg data\n",
    "exp = EEGexp(data_folder)\n",
    "eegdata = exp.load_eegdata(frequency=sample_rate, return_type='pd')\n",
    "\n",
    "# load other data (running, iso etc)\n",
    "print('Loading other data...')\n",
    "running_speed = exp.load_running(return_type='pd')\n",
    "try:\n",
    "    iso = exp.load_analog_iso(return_type='pd')\n",
    "except:\n",
    "    iso = None\n",
    "\n",
    "# locate valid channels (some channels can be disconnected and we want to ignore them in the analysis)\n",
    "print('Identifying valid channels...')\n",
    "median_amplitude = eegdata[:sample_rate*300].apply(\n",
    "    utils.median_amplitude, raw=True, axis=0, distance=sample_rate\n",
    ")\n",
    "valid_channels = median_amplitude.index[median_amplitude < 2000].values\n",
    "print('The following channels seem to be correctly connected and report valid data:')\n",
    "print(list(valid_channels))\n",
    "\n",
    "# annotate artifacts with power in high frequencies\n",
    "print('Annotating artifacts...')\n",
    "hf_annots = pd.Series(\n",
    "    eegdata[valid_channels].apply(\n",
    "        find_hf_annotations, axis=0,\n",
    "        sample_rate=sample_rate, fmin=300, pmin=0.25\n",
    "    ).mean(axis=1),\n",
    "    name='artifact'\n",
    ")\n",
    "\n",
    "# automatically annotate anesthesia epochs\n",
    "iso_first_on = (iso>4).idxmax()\n",
    "print('iso on at', iso_first_on)\n",
    "iso_first_mid = ((iso[iso.index>iso_first_on]>1)&(iso[iso.index>iso_first_on]<4)).idxmax()\n",
    "print('iso reduced at', iso_first_mid)\n",
    "iso_first_off = (iso>1)[::-1].idxmax()\n",
    "print('iso off at', iso_first_off)\n",
    "recovery_first_jump = (hf_annots>4)[hf_annots.index>iso_first_off].idxmax()\n",
    "\n",
    "epochs = pd.Series(\n",
    "    index = [0, iso_first_on-0.001, iso_first_on+0.001, iso_first_mid-0.001,\n",
    "             iso_first_mid+0.001, iso_first_off-0.001, iso_first_off+0.001,\n",
    "             recovery_first_jump-0.001, recovery_first_jump+0.001, eegdata.index[-1]],\n",
    "    data=['pre', 'pre', 'iso_high', 'iso_high', 'iso_low', 'iso_low',\n",
    "          'early_recovery', 'early_recovery', 'late_recovery', 'late_recovery'],\n",
    "    dtype=pd.CategoricalDtype(\n",
    "        categories=['pre', 'iso_high', 'iso_low', 'early_recovery', 'late_recovery'],\n",
    "        ordered=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "## Generate valid windows\n",
    "Valid meaning windows without artifacts.  \n",
    "Turns out, we can just generate windows very easily, and validate them on the fly using a validity Series, `invalid_times`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 4\n",
    "invalid_times = (hf_annots>thresh)\n",
    "invalid_times[invalid_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre # invalid windows: 17\n",
      "iso_high # invalid windows: 11\n",
      "iso_low # invalid windows: 0\n",
      "early_recovery # invalid windows: 0\n",
      "late_recovery # invalid windows: 77\n"
     ]
    }
   ],
   "source": [
    "# this is just to quantify invalid windows, but is not used in later analysis\n",
    "valid_windows = {}\n",
    "for epoch in epochs.groupby(epochs):\n",
    "    invalid = get_windows((hf_annots>thresh)&(hf_annots.index<epoch[1].index[1])&(hf_annots.index>epoch[1].index[0]), coalesce=4, min_length=0.2)\n",
    "    print(epoch[0], '# invalid windows:', len(invalid))\n",
    "    valid = [(invalid[i][1], invalid[i+1][0]) for i in range(len(invalid)-1)]\n",
    "    valid_windows[epoch[0]] = valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "## Create state vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_lfp(aligned_df, sample_rate, winsize):\n",
    "    \"\"\"\n",
    "    Simply returns the mean absolute value of signal\n",
    "    Instead, it could first find the envelope and return mean amplitude of that\n",
    "    \"\"\"\n",
    "    if ((aligned_df.artifact).sum() > 0) | (len(aligned_df) < winsize * sample_rate):\n",
    "        # window overlaps with artifact or window too short, so return nan\n",
    "        return aligned_df[valid_channels].mean()*np.nan\n",
    "    else:\n",
    "        return aligned_df[valid_channels].abs().mean()\n",
    "    return\n",
    "\n",
    "def spectral_state(aligned_df, sample_rate, winsize):\n",
    "    \"\"\"\n",
    "    Returns the spectral state for a block of time\n",
    "    \"\"\"\n",
    "    if ((aligned_df.artifact).sum() > 0) | (len(aligned_df) < winsize * sample_rate):\n",
    "        # window overlaps with artifact | window too short, so return nan\n",
    "        aligned_df = pd.DataFrame(data=np.zeros((int(sample_rate*winsize), len(valid_channels))))\n",
    "        return pd.Series(differentiation.spectral_states(\n",
    "            sample_rate=sample_rate,\n",
    "            window_length=winsize,\n",
    "            data=aligned_df.values[:int(winsize*sample_rate)].T\n",
    "        )[-1])*np.nan\n",
    "    else:\n",
    "        spec = differentiation.spectral_states(\n",
    "            sample_rate=sample_rate,\n",
    "            window_length=winsize,\n",
    "            data=aligned_df[valid_channels].values[:int(winsize*sample_rate)].T\n",
    "        )[-1]\n",
    "        return pd.Series(spec)\n",
    "\n",
    "def spectral_differentiation(aligned_df, sample_rate, winsize, state_length):\n",
    "    if ((aligned_df.artifact).sum() > 0) | (len(aligned_df) < winsize * sample_rate):\n",
    "        return pd.Series([np.nan]*int((winsize/state_length)*(winsize/state_length-1)/2))\n",
    "    return pd.Series(\n",
    "        differentiation.spectral_differentiation(\n",
    "            aligned_df[valid_channels].values[:int(winsize*sample_rate)].T,\n",
    "            sample_rate=sample_rate, window_length=state_length\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINSIZE_s = 9\n",
    "func = spectral_state\n",
    "# how many valid windows do we have of that length?\n",
    "windows = pd.Series(index=eegdata.index, data=(eegdata.index/WINSIZE_s).astype(int), name='window')\n",
    "aligned_windows = pd.concat([eegdata[valid_channels], windows, invalid_times.reindex(windows.index, method='nearest')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245, 326279)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = aligned_windows.groupby('window').apply(func, sample_rate=sample_rate, winsize=WINSIZE_s).dropna()\n",
    "state_times = windows.groupby(windows).apply(lambda x: np.mean(x.index))[states.index]\n",
    "states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "## UMAP on temporal states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "aligned_running_windows = pd.concat([running_speed.reindex(windows.index, method='nearest'), windows, invalid_times.reindex(windows.index, method='nearest')], axis=1)\n",
    "mean_speed_by_win = aligned_running_windows.groupby('window').apply(lambda x: x.running_speed.mean())\n",
    "v_max = mean_speed_by_win.max()\n",
    "v_min = mean_speed_by_win.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "spec_df = aligned_windows.groupby('window').apply(\n",
    "    spectral_differentiation, sample_rate=sample_rate, winsize=WINSIZE_s, state_length=WINSIZE_s/30\n",
    ").dropna().median(axis=1)\n",
    "d_max = spec_df.max()\n",
    "d_min = spec_df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(\n",
    "    n_neighbors=10,\n",
    "    min_dist=0.01,\n",
    ")\n",
    "reducer.fit(states.values)\n",
    "embedding = reducer.transform(states.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7458250479a54c91a0554c86f87e5c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = 'differentiation'\n",
    "# label = 'running'\n",
    "# label = 'epoch'\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(6, 4), tight_layout=True)\n",
    "if label == 'running':\n",
    "    c=mean_speed_by_win.loc[states.index].map(lambda x: cm.Accent((x-v_min)/(v_max-v_min), 0.4)) # color by running speed\n",
    "    plt.colorbar(cm.ScalarMappable(norm=mpl.colors.Normalize(vmin=v_min, vmax=v_max), cmap=cm.Accent), label='Velocity')\n",
    "if label == 'differentiation':\n",
    "    c=spec_df.loc[states.index].map(lambda x: cm.Reds((x-d_min)/(d_max-d_min), 0.8)) # color by differentiation\n",
    "    plt.colorbar(cm.ScalarMappable(norm=mpl.colors.Normalize(vmin=d_min, vmax=d_max), cmap=cm.Reds), label='Differentiation')\n",
    "if label == 'epoch':\n",
    "    c=[x(0.7, 0.8) for x in epochs.reindex(state_times, method='nearest').apply(lambda x: epoch_cms[x])] # color by epoch\n",
    "    label_patches = [patches.Patch(color=epoch_cms[ep](0.7, 0.8), label=ep) for ep in epochs.dtype.categories]\n",
    "    ax.legend(handles=label_patches, loc=(1.02, 0))\n",
    "ax.set_xlabel('umap 1')\n",
    "ax.set_ylabel('umap 2')\n",
    "ax.set_title('{0:.2f} s window, {1:s}'.format(WINSIZE_s, func.__name__), fontsize=10)\n",
    "\n",
    "sc = ax.scatter(embedding[:, 0], embedding[:, 1], c=c);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "## UMAP on channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "states['epoch'] = epochs.reindex(state_times, method='nearest').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_umap(df, axes):\n",
    "    e = df.epoch.iloc[0]\n",
    "    ax = axes[list(epochs.cat.categories).index(e)]\n",
    "    df = df[valid_channels]\n",
    "    reducer = umap.UMAP(\n",
    "        n_neighbors=6,\n",
    "        min_dist=0.1,\n",
    "    )\n",
    "    reducer.fit(df.values.T)\n",
    "    embedding = reducer.transform(df.values.T)\n",
    "\n",
    "    ax.scatter(\n",
    "        embedding[:, 0], embedding[:, 1],\n",
    "        c=[cm.Accent(i/len(valid_channels), 0.9) for i in range(len(valid_channels))]\n",
    "    )\n",
    "    label_patches = [patches.Patch(color=cm.Accent(i/len(valid_channels), 0.9), label=i) for i in range(len(valid_channels))]\n",
    "#     ax.legend(handles=label_patches, loc=(1.02, 0))\n",
    "    ax.set_xlabel('umap 1')\n",
    "    ax.set_ylabel('umap 2')\n",
    "    ax.set_title('{0:.2f} s window, {1:s}\\n{2:s}'.format(WINSIZE_s, func.__name__, e), fontsize=10)\n",
    "    return (reducer, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e974baf8ac5c4347af01bb8b734cb9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(1, len(epochs.cat.categories), figsize=(3*len(epochs.cat.categories), 3), tight_layout=True)\n",
    "ret = states.groupby('epoch').apply(plot_umap, axes=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31172"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zapnzip",
   "language": "python",
   "name": "zapnzip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
